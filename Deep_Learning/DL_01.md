# Tensorflow



### Tensorfolw 란

- 2015년 구글에서 인공지능을 파트인 구글브레인에서 개발하고 오픈소스 라이선 스(Apache 2.0)로 공개
- Data Flow Graph를 기반으로 하는 numerical computation을 하는 오픈 소스 소프트웨어 라이브러리
- 딥러닝에 최적화된 프로그램
- 코드 수정 없이 데스크탑, 서버 혹은 모바일 디바이스에서 웬만하면 모두 사용 가능하며, CPU, GPU, TPU를 사용하여 연산을 수행한다.
- 아이디어 테스트(POC)에서 서비스 단계까지 모두 이용 가능하다.
  - 아이디어 테스트란 제일 초기 단계에 '이런 게 가능할까?' 하며 실행해 보는 것
  - 보통은 POC 단계에서 실행한 것은 서비스 단계와 다른데, 텐서플로우는 그렇지 않다.
- 계산 구조와 목표 함수만 정의하면 자동으로 미분 계산 처리



---



### Data Flow Gragh

- 수치 계산과 데이터의 흐름을 노드(node)와 엣지(edge)를 사용해 양방향 그래프로 표현한다.
  - 엣지 : 노드 사이를 이동하는 다차원 데이터 텐서(행렬)로, 쉽게 데이터의 이동이다.
  - 노드(뉴런) : 수치 연산을 한다.



---



### 데이터 준비

```python
import tensorflow as tf
from tensorflow import keras

import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)
```

​	텐서플로우 모듈을 가져온다. 보통 keras와 함께 사용한다.



---



### 실습데이터 활용

```python
fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
```

​	텐서플로우에서 제공하는 기본 데이터셋 중 fashion_mnist 데이터셋을 불러온다. 텐서플로우는 이전 머신러닝과 달리 쉽게 train과 test를 split 할 수 있다.



```python
>>> train_images.shape
(60000, 28, 28)

>>> test_images.shape
(10000, 28, 28)

>>> train_labels
array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
```

​	train과 test가 60000 : 10000으로 구분되었고, 각각 28 x 28 픽셀 구조이다. 그리고 label(카테고리)이 array에 숫자로 되어 있는데, 이것을 보기 쉽게 문자로 작업해 주었다.



---



### 데이터 전처리

```python
plt.figure(figsize = (10,10))
plt.imshow(train_images[1])
plt.colorbar()
plt.grid(False)
plt.show()

train_images = train_images / 255.0
test_images = test_images / 255.0
plt.figure(figsize=(10,10))
plt.imshow(train_images[1])
plt.colorbar()
plt.grid(False)
plt.show()
```

​	matplotlib을 통해 image 확인을 해본다. 확인을 해보면 colorbar가 0~255로 정수로 되어 있는데, 이를 소수로 바꿔주는 작업을 해야 한다. 그래서 각각 255.0으로 나눠 0~1.0으로 바꾼다.



```python
plt.figure(figsize = (10,10))
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_images[i], cmap=plt.cm.binary)
  plt.xlabel(class_names[train_labels[i]])
plt.show()
```

​	이제 subplot으로 image들을 확인해 보면 흑백으로 나타난 것을 확인할 수 있을 것이다. 그리고 xlabel을 아까 설정한 class_names로 해주어 이미지마다 카테고리명이 함께 보일 것이다.



---



### 모델구성

```python
model = keras.Sequential([keras.layers.Flatten(input_shape=(28,28)),
                          keras.layers.Dense(128, activation=tf.nn.relu),
                          keras.layers.Dense(10, activation=tf.nn.softmax)])
```

​	모델을 구성하는 단계 중 첫 번째 단계는 층을 구성하는 단계로, 모델을 컴파일 하기 전 단계이다. 컴파일이란 계산 구조와 모델 정의를 하면 그 정보를 텐서플로우에 전달하는 것이다. 컴파일을 해야만 모델 학습을 할 수 있다.

​	model이라는 변수에 층을 설정하는데, 3개의 층을 설정할 것이다. 먼저 Flatten을 쌓고, Dense, 그리고 Dense 순으로 쌓는다.

​	Flatten layer는 2차원인 데이터를 1차원으로 풀어주는 작업을 한다.

28 x 28(2D)였던 데이터가 [ . . . . . . . . ] 이렇게 1차원으로 바뀌고, 바뀐 데이터는 다시 Dense로 연결된다.

​	Dense의 각 뉴런에 flat 한 1차원 데이터들이 연결된다. 예를 들어 dense를 128로 설정하면 뉴런이 128개라는 건데, 각각의 뉴런 한 개당 flat 한 데이터가 연결된다. 그래서 128 x 28 x 28 만큼의 데이터가 형성된다.

​	그리고 마지막 Dense를 10으로 설정해, 여기에 이전 dense의 뉴런이 각각 연결된다. 즉 (128 x 28 x 28) x 10 만큼의 데이터가 생성된다.

> 뉴런이란 각각의 입력값이 들어오면 결과를 출력하는 것으로, 여러 뉴런의 모임이 Dense layer이다. 앞서 말한 노드와 같은 의미다.





```python
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
```

​	이제 모델 컴파일을 해준다. 컴파일에는 청 3가지 개념이 있다. 손실 함수(loss function), 옵티마이저(optimizer), 지표(metrics).

​	손실 함수는 훈련 시 모델의 오차를 측정하며, 손실 함수가 최소화되어야 좋다. 옵티마이저는 모델의 업데이트 방법을 결정하며, 업데이트가 되어야만 에러를 줄일 수가 있다. 지표는 훈련 단계와 테스트 단계를 모니터링하기 위해 사용한다.



```python
model.fit(train_images, train_labels, epochs=5)
```

​	train 데이터로 모델을 학습시킨다. epochs는 학습을 몇 번 반복할지를 설정하는 파라메타로 많이 하면 좋지만 어느 정도 수준이 되면 성능이 더 좋아지지 않는다.



---



### 정확도 평가

```python
test_loss, test_acc = model.evaluate(test_images, test_labels)

>>> test_loss # 손실
0.3585861921310425

>>> test_acc # 정확도
0.8716999888420105
```

​	test의 loss와 accuracy를 확인한다. accuracy가 0.87이라는 것은 정확도가 87%로 만약 100개의 데이터가 있으면 87개는 맞는다는 의미다.



---



### 예측 만들기

```python
>>> predictions = model.predict(test_images)
>>> predictions[0]
array([9.6172425e-06, 1.1363539e-08, 7.1610778e-08, 6.3189297e-08,
       1.0152608e-06, 5.5546830e-03, 6.4864253e-07, 1.9721698e-02,
       1.1473103e-05, 9.7470063e-01], dtype=float32)
```

​	test 이미지를 예측한 모델을 변수에 넣어 가장 첫 번째 예측 모델을 확인하면 array로 값이 나오는 것을 확인할 수 있다. 이 array는 카테고리 10개별로 데이터가 그 카테고리에 맞을 확률을 의미한다. 여기서 카테고리가 10개인 이유는 앞서 label이 0~9까지이기 때문이고, array가 10개인 이유는 모델 구성에서 Dense layer를 최종적으로 10개로 설정했기 때문이다.

​	그리고 array 데이터 10개의 총합은 항상 1이 나온다. 그 이유는 확률이기 때문이다.



```python
>>> np.argmax(predictions[0])
9

>>> test_labels[0]
9
```

​	argmax는 가장 수가 큰 인덱스를 반환하는 함수로 여기서는 정확도가 가장 높은 label을 반환한다. 그리고 test_labels과 비교해 보면 두 개 모두 9로 예측이 잘 된 것을 확인할 수 있다.

 

---



### 시각화로 확인하기

```python
plt.figure(figsize=(10,10))
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid('off')
  plt.imshow(test_images[i], cmap=plt.cm.binary)
  predicted_label = np.argmax(predictions[i])
  true_label = test_labels[i]
  if predicted_label == true_label:
    color = 'green'
  else:
    color = 'red'
  plt.xlabel("{} ({})".format(class_names[predicted_label],
                               class_names[true_label]), color = color)
```

​	subplot으로 이미지를 확인한다. 이때 잘 맞으면 xlabel이 초록색일 것이고, 예측이 틀리면 빨간색으로 나타날 것이다.



---



### 막대그래프와 함께 시각화

```python
def plot_image(i, predictions_array, true_label, img):
  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                        100*np.max(predictions_array),
                                        class_names[true_label]), color = color)
```

​	불러올 이미지에 대한 함수 정의이다.



```python
def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array[i], true_label[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color = '#777777')
  plt.ylim([0, 1])
  predicted_label = np.argmax([predictions_array])

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')
```

​	정확도를 확인하는 막대그래프 함수 정의이다.



```python
i = 0
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions, test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions, test_labels)
plt.show()
```

​	첫 번째 이미지로 이미지와 정확도를 확인해 본다.



```python
num_rows = 5
num_cols = 3
num_images = num_rows * num_cols
plt.figure(figsize = (2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions, test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions, test_labels)
plt.show()
```

​	여러 개의 파일을 확인해 본다.



---



### activation

​	출력값이 있으면 거기에 함수를 씌워 결과를 출력해준다. 대표적으로 relu가 있는데, relu는 입력값이 음수면 출력값을 0으로 반환하고, 양수면 그대로 값을 반환한다. activation 함수는 매우 다양하다.



---



### optimizer

​	옵티마이저는 loss 값을 최소화 하기위해 가중치를 update 해주는 방법이다. 그 중 adam은 데이터 흐름의 방향과 반대 방향으로 가중치를 조정해 loss 값을 조절해준다. 그리고 학습이 끝나면 조정한 가중치가 고정된다.

​	그리고 가중치에 따라서 예측값이 달라지므로 가중치를 층의 상태라고도 표현한다.
