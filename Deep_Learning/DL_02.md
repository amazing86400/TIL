# NeuralNetwork



### 신경망의 구조



![신경망 구조](E:\amazing\Bigdata\code\git\TIL\Deep_Learning\신경망 구조.jpg)



- layer : 네트워크(또는 모델)를 구성하는 층
- target : 입력 데이터와 그에 상응하는 타깃
- loss function : 학습에 사용할 피드백 신호를 정의하는 손실 함수
- optimizer : 학습 진행 방식을 결정하는 옵티마이저

​	입력값 X를 layer에 넣으면 예측값으로 Y'을 반환하는데, 이것을 target인 Y와 비교하여 loss function을 구한다. 이때 나오는 값이 바로 error이며, 이것을 최소화하기 위해 업데이트를 도와주는 것이 바로 optimizer이다. optimizer는 가중치를 조정한다.



----



### layer

- 딥러닝의 구성단위
- 하나 이상의 텐서를 입력받아 하나 이상의 텐서를 출력하는 데이터 처리 모듈이다.
- 대부분의 경우 가중치(weights)라는 층의 상태를 갖는다.
  - 층의 상태를 갖는다는 것은 모든 값들은 가중치에 따라 값이 결정되므로 층의 상태를 갖는다고 말한다.
  - 하지만 모두 가중치가 존재하는 것은 아니다.(flatten은 없음)
- 가중치는 확률적 경사 하강법에 의해 학습되는 하나 이상의 텐서이며 여기에 네트워크가 학습한 지식이 담겨 있다.
  - 학습을 통해 가중치가 고정되어 있으면 이것을 디스크에 저장하여 다음에 사용할 때, 디스크에 있는 것을 사용하면 된다.
  - 다시 학습을 해도 결과는 똑같이 나올 것이다.
- 층마다 적절한 텐서 포맷과 데이터 처리 방식이 다르다.
  - (samples, features) 크기의 2D 텐서가 저장된 간단한 벡터 데이터는 완전 연결층(fully connected layer)나 밀집층(dense layer)이라고도 불리는 밀집 연결층(densely connected layer)에 의해 처리되는 경우가 많다.
  - (samples, timesteps, features) 크기의 3D 텐서로 저장된 시퀀스 데이터는 보통 LSTM 같은 순환층(recurrent layer)에 의해 처리한다.
  - 4D 텐서로 저장되어 있는 이미지 데이터는 일반적으로 2D 합성곱 층(convolution layer)에 의해 처리한다.
- 딥러닝의 레고 블록처럼 생각할 수 있다.(층으로 하나씩 쌓음)
- 아무 층이나 쌓는 것이 아닌, 호환 가능한 층들을 엮어 데이터 변환 파이프라인(pipeline)을 구성하여 딥러닝 모델을 만든다.
- keras에서는 모델에 추가된 층을 자동으로 상위 층의 크기에 맞추어 주기 때문에 호환성을 걱정할 필요가 없다.



---



### Model

- 층의 네트워크
- 하나의 입력을 하나의 출력으로 매핑하는 층을 순서대로 쌓는 것(일반적인 예)
- 머신러닝 >> 가능성 있는 공간을 사전에 정의하고 피드백 신호의 도움을 받아 입력 데이터에 대한 유용한 변환을 찾는 것
- 규칙이나 공식이 따로 없기 때문에 딱 맞는 네트워크 구조를 찾아내는 것은 과학보다 예술에 가깝다.



---



### Loss function and Optimizer

- 손실 함수(목적함수-objective function) : 훈련하는 동안 최소화될 값. 즉, 주어진 문제에 대한 성공 지표가 될 수 있다.
- 옵티마이저(optimizer) : 손실 함수를 기반으로 네트워크가 어떻게 업데이트될지 결정한다. 확률적 경사 하강법(SGD)을 구현한다.(랜덤으로 설정하여 줄여나감)
- 문제에 맞는 올바른 목적함수를 선택하는 것이 매우 중요하다. 이게 왜 중요하냐면 올바르지 못한 목적함수가 선택될 경우 네트워크가 손실을 최소화하기 위해 편법을 사용할 수가 있기 때문이다.
  - 모든 인류의 평균 행복지수를 최대화하기 위해 행복지수가 낮은 지역의 인구를 줄이는 것
- 분류, 회귀, 시퀀스 예측 같은 일반적인 문제에서는 올바른 손실 함수를 선택하는 간단한 지침이 존재한다.(가이드라인)
  - 2개의 클래스 분류 - 이진 크로스엔트로피(binary crossentropy)
  - 여러 개의 클래스 분류 - 범주형 크로스엔트로피(categorical crossentropy)
  - 회귀 - 평균 제곱 오차(mean square error, MSE)
  - 시퀀스 학습 - CTC(Connected Temporal Classification)

